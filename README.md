### Demo Video:
https://www.youtube.com/watch?v=Jasby95lXDI

### Inspiration:
We believe technology should empower people, not limit them. Many visually impaired individuals face daily challenges navigating unfamiliar spaces or locating essential items. Traditional mobility aids provide some assistance, but we saw an opportunity to take it further—blending artificial intelligence with real-world functionality. Our mission is to create a device that’s not just helpful, but truly life-changing. By combining smart object recognition, voice interaction, and obstacle detection, we are breaking barriers and opening doors to a more accessible world for all.

### What it does:
Equipped with a powerful AI-driven object recognition system and an intuitive voice command feature, it allows users to simply say the name of the item they are looking for. The built-in webcam scans the environment, and if the object is detected, the device instantly announces its location, guiding the user toward it. To ensure safety, an ultrasonic sensor continuously monitors the surroundings, beeping if the user gets too close to an obstacle. It's more than just a tool—it’s independence, freedom, and confidence in a single device!

### Challenges we ran into:
Adapting to multiple pivots due to unexpected bugs in object detection. Debugging the computer’s speaker issue by adding a few lines of code. Learning Arduino from scratch during the hackathon, as none of us had prior experience. Resolving speaker output issues by removing a resistor that was preventing sound. Applying Ohm’s Law (V = IR) to troubleshoot and refine our circuit design.

### What's next for SightSense:
Enhance model training to improve person recognition accuracy. Integrate the OpenAI API for directional guidance towards detected objects. Upgrade to a more advanced sensor, such as the Arducam, for superior object detection (given the resource constraints of this hackathon, we worked with what was available).

### DevPost Link:
https://devpost.com/software/sightsense-hoyi1d
